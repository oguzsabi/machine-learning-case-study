{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Job Title', 'Salary Estimate', 'Job Description',\n",
       "       'Rating', 'Company Name', 'Location', 'Headquarters', 'Size', 'Founded',\n",
       "       'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors',\n",
       "       'hourly', 'employer_provided', 'min_salary', 'max_salary', 'avg_salary',\n",
       "       'company_txt', 'job_state', 'same_state', 'age', 'python_yn', 'R_yn',\n",
       "       'spark', 'aws', 'excel', 'job_simp', 'seniority', 'desc_len',\n",
       "       'num_comp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statistics\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('eda_data_old.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['avg_salary', 'Rating', 'Size', 'Type of ownership', 'Industry',\n",
       "       'Sector', 'Revenue', 'num_comp', 'hourly', 'employer_provided',\n",
       "       'job_state', 'same_state', 'age', 'python_yn', 'spark', 'aws', 'excel',\n",
       "       'job_simp', 'seniority', 'desc_len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# picking the relevant columns\n",
    "df_model = df[\n",
    "    ['avg_salary', 'Rating', 'Size', 'Type of ownership', 'Industry', 'Sector', 'Revenue', 'num_comp', 'hourly',\n",
    "     'employer_provided',\n",
    "     'job_state', 'same_state', 'age', 'python_yn', 'spark', 'aws', 'excel', 'job_simp', 'seniority', 'desc_len']]\n",
    "\n",
    "df_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['avg_salary', 'Rating', 'num_comp', 'hourly', 'employer_provided',\n",
       "       'same_state', 'age', 'python_yn', 'spark', 'aws',\n",
       "       ...\n",
       "       'job_simp_analyst', 'job_simp_data engineer', 'job_simp_data scientist',\n",
       "       'job_simp_director', 'job_simp_manager', 'job_simp_mle', 'job_simp_na',\n",
       "       'seniority_jr', 'seniority_na', 'seniority_senior'],\n",
       "      dtype='object', length=178)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dummy data\n",
    "df_dum = pd.get_dummies(df_model)\n",
    "\n",
    "df_dum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = df_dum.drop('avg_salary', axis=1)\n",
    "y = df_dum.avg_salary.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test.to_csv('X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple linear regression\n",
    "X_sm = X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X_sm)\n",
    "model.fit().summary()\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "np.mean(cross_val_score(lm, X_train, y_train, scoring='neg_mean_absolute_error', cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regression\n",
    "lm_l = Lasso(alpha=.13)\n",
    "lm_l.fit(X_train, y_train)\n",
    "np.mean(cross_val_score(lm_l, X_train, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "alpha = []\n",
    "error = []\n",
    "\n",
    "for i in range(1, 100):\n",
    "    alpha.append(i / 100)\n",
    "    lml = Lasso(alpha=(i / 100))\n",
    "    error.append(np.mean(cross_val_score(lml, X_train, y_train, scoring='neg_mean_absolute_error', cv=3)))\n",
    "\n",
    "plt.plot(alpha, error)\n",
    "\n",
    "err = tuple(zip(alpha, error))\n",
    "df_err = pd.DataFrame(err, columns=['alpha', 'error'])\n",
    "df_err = df_err[df_err.error == max(df_err.error)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "np.mean(cross_val_score(rf, X_train, y_train, scoring='neg_mean_absolute_error', cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune models GridsearchCV\n",
    "\n",
    "parameters = {'n_estimators': range(10, 300, 10), 'criterion': ('friedman_mse', 'absolute_error'), 'max_features': ('sqrt', 'log2')}\n",
    "\n",
    "gs = GridSearchCV(rf, parameters, scoring='neg_mean_absolute_error', cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_score = gs.best_score_\n",
    "best_estimator = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test ensembles \n",
    "tpred_lm = lm.predict(X_test)\n",
    "tpred_lml = lm_l.predict(X_test)\n",
    "tpred_rf = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "tpred_lm_err = mean_absolute_error(y_test, tpred_lm)\n",
    "tpred_lml_err = mean_absolute_error(y_test, tpred_lml)\n",
    "tpred_rf_err = mean_absolute_error(y_test, tpred_rf)\n",
    "tpred_lm_rf_err = mean_absolute_error(y_test, (tpred_lm + tpred_rf) / 2)\n",
    "\n",
    "print(\"mse lm: \" + str(tpred_lm_err))\n",
    "print(\"mse lml: \" + str(tpred_lml_err))\n",
    "print(\"mse rf: \" + str(tpred_rf_err))\n",
    "print(\"mse lm+rf: \" + str(tpred_lm_rf_err))\n",
    "print(\"\\n\")\n",
    "print(\"lm: \" + str(statistics.mean(tpred_lm)))\n",
    "print(\"lml: \" + str(statistics.mean(tpred_lml)))\n",
    "print(\"rf: \" + str(statistics.mean(tpred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "data = {\n",
    "    'lm': tpred_lm,\n",
    "    'lml': tpred_lml,\n",
    "    'rf': tpred_rf,\n",
    "    'y-real': y_test\n",
    "}\n",
    "df_final = pd.DataFrame(data)\n",
    "\n",
    "df_final.to_csv('final_results.csv', index=False)\n",
    "\n",
    "joblib.dump(gs, \"./random_forest.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
